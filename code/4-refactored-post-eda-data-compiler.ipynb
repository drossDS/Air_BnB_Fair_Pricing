{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8823ede5-8674-46fa-9790-46af979d8fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For tesxt:\n",
    "import re\n",
    "\n",
    "# For times:\n",
    "import time\n",
    "\n",
    "# Set a random seed for imputation\n",
    "#  Source:  https://numpy.org/doc/stable/reference/random/generated/numpy.random.seed.html\n",
    "np.random.seed(42)\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818cfdc1-de00-41a8-9ed2-927ddec24c8b",
   "metadata": {},
   "source": [
    "# Read-in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33d00783-8649-4dd6-91d7-876943982bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Training Data\n",
    "lstn = pd.read_csv('../data/listings_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04e79290-03e3-462e-b8ad-130dc7c8c03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, this file has been added to the gitignore file and is NOT located in the repository\n",
    "geodata = pd.read_csv('../data/lat_lng_data.csv')\n",
    "\n",
    "latitudes = list(geodata.lat)\n",
    "longitudes = list(geodata.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2194d96-0848-4b94-9ad0-c4ba11c058a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Drop Un-needed Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2494824a-083e-4b90-a6b3-5bc320603d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_dropper(data_frame):\n",
    "    data_frame.drop(columns = [\n",
    "        'listing_url', 'scrape_id', 'last_scraped', 'source',\n",
    "        'picture_url', 'host_url', 'host_name', 'host_thumbnail_url', 'host_picture_url',\n",
    "        'neighbourhood','neighbourhood_group_cleansed', 'minimum_minimum_nights',\n",
    "        'maximum_minimum_nights', 'minimum_maximum_nights', 'maximum_maximum_nights', \n",
    "        'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'calendar_updated',\n",
    "        'calendar_last_scraped', 'bathrooms', 'first_review', 'last_review',\n",
    "        'id', 'host_id',\n",
    "    ], inplace = True)\n",
    "\n",
    "    # For now, these columsn will also be dropped unless time allows for them to be processed:\n",
    "    data_frame.drop(columns = [\n",
    "        'host_location', 'host_neighbourhood', 'review_scores_rating', 'review_scores_accuracy',\n",
    "        'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication',\n",
    "        'review_scores_location', 'review_scores_value', 'license'\n",
    "    ], inplace = True)\n",
    "    \n",
    "    # No need to reutrn the dataframe as the inplace functions carry over to the input dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71f6646-3453-4b85-bc57-02ac131f1ffb",
   "metadata": {},
   "source": [
    "# Fix Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f6e20e3-fd0f-4884-933c-2fcde3858fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Since the null values are not a very big percentage of the total data (though not a small percentage either),\n",
    "the data will be imputed with the median value.\n",
    "\n",
    "In order to do that, the percetnages need to be convereted where possible, so that the nulls can be imputed\n",
    "with the median value.\n",
    "\n",
    "The pcnt_floater functionwill be copied over here.  This is necessary as there are null values in these columns\n",
    "which cannot be simply converted within the lambda function because there is no percentage sign.\n",
    "'''\n",
    "\n",
    "# This function will attempt to convert a string percentage value into a float\n",
    "#  Source for help:  https://www.w3schools.com/python/python_try_except.asp\n",
    "def pcnt_floater(x):\n",
    "    try:\n",
    "        return float(x.replace('%', '').strip())\n",
    "    except:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea8d2bc-8076-442b-972a-a6e0ede289b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_fixer(data_frame):\n",
    "\n",
    "# FIX PRICE:  The dolar signs must be removed from the prices and numbers converted to float values\n",
    "    data_frame.price = data_frame.price.apply(lambda x: float(x.replace('$','').replace(',','').strip()))\n",
    "\n",
    "    # FIX HOST SINCE:  Convert to datetime then to epoch time in days\n",
    "    '''\n",
    "    The method used below to convert to epoch time was discovered with the help of ChatGPT.\n",
    "    Per the lead instructor, it is ok to use ChatGPT is a search tool provided that we provide the\n",
    "    question that was asked:\n",
    "\n",
    "    Question:  'in python, I want to convert a pandas datetime object to epoch time'\n",
    "\n",
    "    Additional help from:  https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html\n",
    "    '''\n",
    "\n",
    "    # The strings are converted to date time, then to epoch time with '.timestamp()'\n",
    "    # The epoch time is then divided by the product the number of hours and seconds per day\n",
    "    #   to get the number of days since the epoch time origin \n",
    "    data_frame['host_since'] = pd.to_datetime(data_frame['host_since']).apply(lambda x: x.timestamp()/(3600*24))\n",
    "\n",
    "    # FIX RESPONSE & ACCEPTANCE RATES:  Remove percentages\n",
    "    # Convert percentages where they can be converted\n",
    "    data_frame.host_acceptance_rate = data_frame.host_acceptance_rate.apply(lambda x: pcnt_floater(x))\n",
    "    data_frame.host_response_rate = data_frame.host_response_rate.apply(lambda x: pcnt_floater(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fae4b4-de3c-4a51-9219-b9864f0f1147",
   "metadata": {},
   "source": [
    "# Impute Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db115cfb-62c6-43e0-a7c8-4b3cd3bea169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_imputer(data_frame):\n",
    "    # Impute missing text information with 'no_text_entered' into the following columns\n",
    "    nte_cols = ['description', 'neighborhood_overview','host_about', 'host_response_time']\n",
    "\n",
    "    for col in nte_cols:\n",
    "        data_frame[col].fillna('no_text_entered', inplace = True)\n",
    "\n",
    "    # Impute missing data with the median in the following columns\n",
    "    median_cols = ['host_response_rate', 'host_acceptance_rate', 'bedrooms', 'beds']\n",
    "\n",
    "    for col in median_cols:\n",
    "        data_frame[col].fillna(data_frame[col].median(), inplace = True)\n",
    "\n",
    "    # Impute missing values with the mode in the following columns\n",
    "    data_frame.host_is_superhost.fillna(data_frame.host_is_superhost.mode()[0], inplace = True)\n",
    "    data_frame.bathrooms_text.fillna(data_frame.bathrooms_text.mode()[0], inplace = True)\n",
    "\n",
    "    # Impute missing data with 0 in reviews per month\n",
    "    data_frame.reviews_per_month.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fa3f762-c42e-4967-8c5a-0fdecb1560d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify imputation\n",
    "sum(lstn.isnull().sum() != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99dab65-a769-4a5f-b7cb-e9e576d2a5a5",
   "metadata": {},
   "source": [
    "# Create Simple Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93d007ca-317c-456f-acb9-834858054ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simp_num_ft(data_frame):\n",
    "    # Create percentage columns for the calculated listings by listing type\n",
    "    data_frame['pcnt_ent_homes'] = round(data_frame['calculated_host_listings_count_entire_homes'] / data_frame['calculated_host_listings_count'], 3)\n",
    "    data_frame['pcnt_private'] = round(data_frame['calculated_host_listings_count_private_rooms'] / data_frame['calculated_host_listings_count'], 3)\n",
    "    data_frame['pcnt_shared'] = round(data_frame['calculated_host_listings_count_shared_rooms'] / data_frame['calculated_host_listings_count'], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d8a3d1-4fac-4cc9-8607-5fc57c86db61",
   "metadata": {},
   "source": [
    "## Add T-Stop Distnace Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f0e77c8-999e-4fd7-9043-90d207678ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This funciton was written around the following source:\n",
    "# https://towardsdatascience.com/create-new-column-based-on-other-columns-pandas-5586d87de73d\n",
    "\n",
    "def min_dist(fn_lat, fn_lng, lat_data, lng_data):\n",
    "    \n",
    "    # Set a minimum distnace well beyond anything that would be derived\n",
    "    min_dist = 90\n",
    "    \n",
    "    # Write a loop to find the minimum (euclidean) distance to every T-stop\n",
    "    for n in range(len(latitudes)):\n",
    "        dist = ((fn_lat - lat_data[n])**2 + (fn_lng - lng_data[n])**2)**0.5\n",
    "        \n",
    "        # Store this distance if smaller than min distance\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "    \n",
    "    return min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce236d8d-e4bd-41bb-8d5e-756285ae7393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_ft_adder(data_frame):\n",
    "    \n",
    "\n",
    "\n",
    "    # Crate a new column with the minimum distance to any T-stop\n",
    "    #  The following source was used to help write this code (note axis = 1 is KEY!):\n",
    "        # https://towardsdatascience.com/create-new-column-based-on-other-columns-pandas-5586d87de73d\n",
    "    data_frame['min_distance'] = data_frame.apply(lambda x: min_dist(x.latitude, x.longitude, latitudes, longitudes), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f02535-a716-4953-b428-309d23421646",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Log Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35d4d080-0a58-4205-98ab-12c1b638048e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>2.427734e+17</td>\n",
       "      <td>3.417200e+17</td>\n",
       "      <td>3.781000e+03</td>\n",
       "      <td>2.537403e+07</td>\n",
       "      <td>4.817395e+07</td>\n",
       "      <td>6.419742e+17</td>\n",
       "      <td>8.493358e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scrape_id</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>2.023032e+13</td>\n",
       "      <td>8.712190e-01</td>\n",
       "      <td>2.023032e+13</td>\n",
       "      <td>2.023032e+13</td>\n",
       "      <td>2.023032e+13</td>\n",
       "      <td>2.023032e+13</td>\n",
       "      <td>2.023032e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_id</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>1.489579e+08</td>\n",
       "      <td>1.409145e+08</td>\n",
       "      <td>4.804000e+03</td>\n",
       "      <td>2.234822e+07</td>\n",
       "      <td>1.074344e+08</td>\n",
       "      <td>2.758496e+08</td>\n",
       "      <td>5.041795e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_listings_count</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>4.782657e+02</td>\n",
       "      <td>1.349140e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>8.400000e+01</td>\n",
       "      <td>4.807000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>6.362462e+02</td>\n",
       "      <td>1.517960e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>1.270000e+02</td>\n",
       "      <td>5.358000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_group_cleansed</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>4.233749e+01</td>\n",
       "      <td>2.711113e-02</td>\n",
       "      <td>4.223530e+01</td>\n",
       "      <td>4.232187e+01</td>\n",
       "      <td>4.234472e+01</td>\n",
       "      <td>4.235431e+01</td>\n",
       "      <td>4.239228e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>-7.108243e+01</td>\n",
       "      <td>3.339280e-02</td>\n",
       "      <td>-7.117349e+01</td>\n",
       "      <td>-7.110049e+01</td>\n",
       "      <td>-7.107316e+01</td>\n",
       "      <td>-7.106081e+01</td>\n",
       "      <td>-7.099600e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>3.181478e+00</td>\n",
       "      <td>2.206180e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>3061.0</td>\n",
       "      <td>1.749102e+00</td>\n",
       "      <td>1.203659e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>3399.0</td>\n",
       "      <td>1.794940e+00</td>\n",
       "      <td>1.438771e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>3.077251e+01</td>\n",
       "      <td>3.985233e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>3.200000e+01</td>\n",
       "      <td>6.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>6.705249e+02</td>\n",
       "      <td>4.525490e+02</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.650000e+02</td>\n",
       "      <td>3.660000e+02</td>\n",
       "      <td>1.125000e+03</td>\n",
       "      <td>1.125000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_minimum_nights</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>3.450963e+01</td>\n",
       "      <td>5.491116e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>3.200000e+01</td>\n",
       "      <td>6.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_minimum_nights</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>6.133535e+01</td>\n",
       "      <td>1.020960e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>9.100000e+01</td>\n",
       "      <td>6.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_maximum_nights</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>2.471306e+06</td>\n",
       "      <td>7.280645e+07</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.650000e+02</td>\n",
       "      <td>1.125000e+03</td>\n",
       "      <td>1.125000e+03</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_maximum_nights</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>8.029963e+06</td>\n",
       "      <td>1.310835e+08</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.650000e+02</td>\n",
       "      <td>1.125000e+03</td>\n",
       "      <td>1.125000e+03</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights_avg_ntm</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>5.949577e+01</td>\n",
       "      <td>9.954917e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.100000e+00</td>\n",
       "      <td>2.740000e+01</td>\n",
       "      <td>9.100000e+01</td>\n",
       "      <td>6.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights_avg_ntm</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>4.669350e+06</td>\n",
       "      <td>8.907709e+07</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.650000e+02</td>\n",
       "      <td>1.125000e+03</td>\n",
       "      <td>1.125000e+03</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calendar_updated</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_30</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>1.025165e+01</td>\n",
       "      <td>1.090363e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_60</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>2.482341e+01</td>\n",
       "      <td>2.191401e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>4.500000e+01</td>\n",
       "      <td>6.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_90</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>4.102991e+01</td>\n",
       "      <td>3.218724e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>4.100000e+01</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>9.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_365</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>1.994921e+02</td>\n",
       "      <td>1.302455e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.900000e+01</td>\n",
       "      <td>2.200000e+02</td>\n",
       "      <td>3.220000e+02</td>\n",
       "      <td>3.650000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>4.128502e+01</td>\n",
       "      <td>8.130071e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>8.210000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews_ltm</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>1.189215e+01</td>\n",
       "      <td>2.142348e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>2.120000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews_l30d</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>6.269773e-01</td>\n",
       "      <td>1.500593e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_rating</th>\n",
       "      <td>2462.0</td>\n",
       "      <td>4.689854e+00</td>\n",
       "      <td>4.539040e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.600000e+00</td>\n",
       "      <td>4.800000e+00</td>\n",
       "      <td>4.967500e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_accuracy</th>\n",
       "      <td>2455.0</td>\n",
       "      <td>4.750916e+00</td>\n",
       "      <td>3.860697e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.690000e+00</td>\n",
       "      <td>4.860000e+00</td>\n",
       "      <td>4.990000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <td>2456.0</td>\n",
       "      <td>4.727101e+00</td>\n",
       "      <td>3.855948e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.630000e+00</td>\n",
       "      <td>4.840000e+00</td>\n",
       "      <td>4.990000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <td>2455.0</td>\n",
       "      <td>4.830175e+00</td>\n",
       "      <td>3.487951e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.810000e+00</td>\n",
       "      <td>4.940000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_communication</th>\n",
       "      <td>2456.0</td>\n",
       "      <td>4.807272e+00</td>\n",
       "      <td>3.793015e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.800000e+00</td>\n",
       "      <td>4.930000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_location</th>\n",
       "      <td>2455.0</td>\n",
       "      <td>4.761043e+00</td>\n",
       "      <td>3.405746e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.670000e+00</td>\n",
       "      <td>4.880000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_value</th>\n",
       "      <td>2455.0</td>\n",
       "      <td>4.603703e+00</td>\n",
       "      <td>4.416080e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.500000e+00</td>\n",
       "      <td>4.700000e+00</td>\n",
       "      <td>4.860000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>6.284699e+01</td>\n",
       "      <td>1.112281e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>4.700000e+01</td>\n",
       "      <td>3.400000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>4.006327e+01</td>\n",
       "      <td>9.447978e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>2.200000e+01</td>\n",
       "      <td>3.400000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>2.271901e+01</td>\n",
       "      <td>7.078624e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.740000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <td>3477.0</td>\n",
       "      <td>1.840667e-02</td>\n",
       "      <td>1.686114e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews_per_month</th>\n",
       "      <td>2462.0</td>\n",
       "      <td>1.694155e+00</td>\n",
       "      <td>1.912049e+00</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>2.700000e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.450000e+00</td>\n",
       "      <td>1.629000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               count          mean  \\\n",
       "id                                            3477.0  2.427734e+17   \n",
       "scrape_id                                     3477.0  2.023032e+13   \n",
       "host_id                                       3477.0  1.489579e+08   \n",
       "host_listings_count                           3477.0  4.782657e+02   \n",
       "host_total_listings_count                     3477.0  6.362462e+02   \n",
       "neighbourhood_group_cleansed                     0.0           NaN   \n",
       "latitude                                      3477.0  4.233749e+01   \n",
       "longitude                                     3477.0 -7.108243e+01   \n",
       "accommodates                                  3477.0  3.181478e+00   \n",
       "bathrooms                                        0.0           NaN   \n",
       "bedrooms                                      3061.0  1.749102e+00   \n",
       "beds                                          3399.0  1.794940e+00   \n",
       "minimum_nights                                3477.0  3.077251e+01   \n",
       "maximum_nights                                3477.0  6.705249e+02   \n",
       "minimum_minimum_nights                        3477.0  3.450963e+01   \n",
       "maximum_minimum_nights                        3477.0  6.133535e+01   \n",
       "minimum_maximum_nights                        3477.0  2.471306e+06   \n",
       "maximum_maximum_nights                        3477.0  8.029963e+06   \n",
       "minimum_nights_avg_ntm                        3477.0  5.949577e+01   \n",
       "maximum_nights_avg_ntm                        3477.0  4.669350e+06   \n",
       "calendar_updated                                 0.0           NaN   \n",
       "availability_30                               3477.0  1.025165e+01   \n",
       "availability_60                               3477.0  2.482341e+01   \n",
       "availability_90                               3477.0  4.102991e+01   \n",
       "availability_365                              3477.0  1.994921e+02   \n",
       "number_of_reviews                             3477.0  4.128502e+01   \n",
       "number_of_reviews_ltm                         3477.0  1.189215e+01   \n",
       "number_of_reviews_l30d                        3477.0  6.269773e-01   \n",
       "review_scores_rating                          2462.0  4.689854e+00   \n",
       "review_scores_accuracy                        2455.0  4.750916e+00   \n",
       "review_scores_cleanliness                     2456.0  4.727101e+00   \n",
       "review_scores_checkin                         2455.0  4.830175e+00   \n",
       "review_scores_communication                   2456.0  4.807272e+00   \n",
       "review_scores_location                        2455.0  4.761043e+00   \n",
       "review_scores_value                           2455.0  4.603703e+00   \n",
       "calculated_host_listings_count                3477.0  6.284699e+01   \n",
       "calculated_host_listings_count_entire_homes   3477.0  4.006327e+01   \n",
       "calculated_host_listings_count_private_rooms  3477.0  2.271901e+01   \n",
       "calculated_host_listings_count_shared_rooms   3477.0  1.840667e-02   \n",
       "reviews_per_month                             2462.0  1.694155e+00   \n",
       "\n",
       "                                                       std           min  \\\n",
       "id                                            3.417200e+17  3.781000e+03   \n",
       "scrape_id                                     8.712190e-01  2.023032e+13   \n",
       "host_id                                       1.409145e+08  4.804000e+03   \n",
       "host_listings_count                           1.349140e+03  1.000000e+00   \n",
       "host_total_listings_count                     1.517960e+03  1.000000e+00   \n",
       "neighbourhood_group_cleansed                           NaN           NaN   \n",
       "latitude                                      2.711113e-02  4.223530e+01   \n",
       "longitude                                     3.339280e-02 -7.117349e+01   \n",
       "accommodates                                  2.206180e+00  1.000000e+00   \n",
       "bathrooms                                              NaN           NaN   \n",
       "bedrooms                                      1.203659e+00  1.000000e+00   \n",
       "beds                                          1.438771e+00  1.000000e+00   \n",
       "minimum_nights                                3.985233e+01  1.000000e+00   \n",
       "maximum_nights                                4.525490e+02  2.000000e+00   \n",
       "minimum_minimum_nights                        5.491116e+01  1.000000e+00   \n",
       "maximum_minimum_nights                        1.020960e+02  1.000000e+00   \n",
       "minimum_maximum_nights                        7.280645e+07  1.000000e+00   \n",
       "maximum_maximum_nights                        1.310835e+08  2.000000e+00   \n",
       "minimum_nights_avg_ntm                        9.954917e+01  1.000000e+00   \n",
       "maximum_nights_avg_ntm                        8.907709e+07  2.000000e+00   \n",
       "calendar_updated                                       NaN           NaN   \n",
       "availability_30                               1.090363e+01  0.000000e+00   \n",
       "availability_60                               2.191401e+01  0.000000e+00   \n",
       "availability_90                               3.218724e+01  0.000000e+00   \n",
       "availability_365                              1.302455e+02  0.000000e+00   \n",
       "number_of_reviews                             8.130071e+01  0.000000e+00   \n",
       "number_of_reviews_ltm                         2.142348e+01  0.000000e+00   \n",
       "number_of_reviews_l30d                        1.500593e+00  0.000000e+00   \n",
       "review_scores_rating                          4.539040e-01  0.000000e+00   \n",
       "review_scores_accuracy                        3.860697e-01  0.000000e+00   \n",
       "review_scores_cleanliness                     3.855948e-01  0.000000e+00   \n",
       "review_scores_checkin                         3.487951e-01  0.000000e+00   \n",
       "review_scores_communication                   3.793015e-01  1.000000e+00   \n",
       "review_scores_location                        3.405746e-01  1.000000e+00   \n",
       "review_scores_value                           4.416080e-01  1.000000e+00   \n",
       "calculated_host_listings_count                1.112281e+02  1.000000e+00   \n",
       "calculated_host_listings_count_entire_homes   9.447978e+01  0.000000e+00   \n",
       "calculated_host_listings_count_private_rooms  7.078624e+01  0.000000e+00   \n",
       "calculated_host_listings_count_shared_rooms   1.686114e-01  0.000000e+00   \n",
       "reviews_per_month                             1.912049e+00  1.000000e-02   \n",
       "\n",
       "                                                       25%           50%  \\\n",
       "id                                            2.537403e+07  4.817395e+07   \n",
       "scrape_id                                     2.023032e+13  2.023032e+13   \n",
       "host_id                                       2.234822e+07  1.074344e+08   \n",
       "host_listings_count                           2.000000e+00  1.200000e+01   \n",
       "host_total_listings_count                     3.000000e+00  1.700000e+01   \n",
       "neighbourhood_group_cleansed                           NaN           NaN   \n",
       "latitude                                      4.232187e+01  4.234472e+01   \n",
       "longitude                                    -7.110049e+01 -7.107316e+01   \n",
       "accommodates                                  2.000000e+00  2.000000e+00   \n",
       "bathrooms                                              NaN           NaN   \n",
       "bedrooms                                      1.000000e+00  1.000000e+00   \n",
       "beds                                          1.000000e+00  1.000000e+00   \n",
       "minimum_nights                                2.000000e+00  2.500000e+01   \n",
       "maximum_nights                                3.650000e+02  3.660000e+02   \n",
       "minimum_minimum_nights                        1.000000e+00  1.000000e+01   \n",
       "maximum_minimum_nights                        3.000000e+00  2.900000e+01   \n",
       "minimum_maximum_nights                        3.650000e+02  1.125000e+03   \n",
       "maximum_maximum_nights                        3.650000e+02  1.125000e+03   \n",
       "minimum_nights_avg_ntm                        2.100000e+00  2.740000e+01   \n",
       "maximum_nights_avg_ntm                        3.650000e+02  1.125000e+03   \n",
       "calendar_updated                                       NaN           NaN   \n",
       "availability_30                               0.000000e+00  7.000000e+00   \n",
       "availability_60                               0.000000e+00  2.300000e+01   \n",
       "availability_90                               7.000000e+00  4.100000e+01   \n",
       "availability_365                              7.900000e+01  2.200000e+02   \n",
       "number_of_reviews                             0.000000e+00  7.000000e+00   \n",
       "number_of_reviews_ltm                         0.000000e+00  1.000000e+00   \n",
       "number_of_reviews_l30d                        0.000000e+00  0.000000e+00   \n",
       "review_scores_rating                          4.600000e+00  4.800000e+00   \n",
       "review_scores_accuracy                        4.690000e+00  4.860000e+00   \n",
       "review_scores_cleanliness                     4.630000e+00  4.840000e+00   \n",
       "review_scores_checkin                         4.810000e+00  4.940000e+00   \n",
       "review_scores_communication                   4.800000e+00  4.930000e+00   \n",
       "review_scores_location                        4.670000e+00  4.880000e+00   \n",
       "review_scores_value                           4.500000e+00  4.700000e+00   \n",
       "calculated_host_listings_count                2.000000e+00  8.000000e+00   \n",
       "calculated_host_listings_count_entire_homes   1.000000e+00  4.000000e+00   \n",
       "calculated_host_listings_count_private_rooms  0.000000e+00  0.000000e+00   \n",
       "calculated_host_listings_count_shared_rooms   0.000000e+00  0.000000e+00   \n",
       "reviews_per_month                             2.700000e-01  1.000000e+00   \n",
       "\n",
       "                                                       75%           max  \n",
       "id                                            6.419742e+17  8.493358e+17  \n",
       "scrape_id                                     2.023032e+13  2.023032e+13  \n",
       "host_id                                       2.758496e+08  5.041795e+08  \n",
       "host_listings_count                           8.400000e+01  4.807000e+03  \n",
       "host_total_listings_count                     1.270000e+02  5.358000e+03  \n",
       "neighbourhood_group_cleansed                           NaN           NaN  \n",
       "latitude                                      4.235431e+01  4.239228e+01  \n",
       "longitude                                    -7.106081e+01 -7.099600e+01  \n",
       "accommodates                                  4.000000e+00  1.600000e+01  \n",
       "bathrooms                                              NaN           NaN  \n",
       "bedrooms                                      2.000000e+00  1.300000e+01  \n",
       "beds                                          2.000000e+00  2.200000e+01  \n",
       "minimum_nights                                3.200000e+01  6.000000e+02  \n",
       "maximum_nights                                1.125000e+03  1.125000e+03  \n",
       "minimum_minimum_nights                        3.200000e+01  6.000000e+02  \n",
       "maximum_minimum_nights                        9.100000e+01  6.000000e+02  \n",
       "minimum_maximum_nights                        1.125000e+03  2.147484e+09  \n",
       "maximum_maximum_nights                        1.125000e+03  2.147484e+09  \n",
       "minimum_nights_avg_ntm                        9.100000e+01  6.000000e+02  \n",
       "maximum_nights_avg_ntm                        1.125000e+03  2.147484e+09  \n",
       "calendar_updated                                       NaN           NaN  \n",
       "availability_30                               1.900000e+01  3.000000e+01  \n",
       "availability_60                               4.500000e+01  6.000000e+01  \n",
       "availability_90                               7.000000e+01  9.000000e+01  \n",
       "availability_365                              3.220000e+02  3.650000e+02  \n",
       "number_of_reviews                             4.400000e+01  8.210000e+02  \n",
       "number_of_reviews_ltm                         1.500000e+01  2.120000e+02  \n",
       "number_of_reviews_l30d                        1.000000e+00  2.200000e+01  \n",
       "review_scores_rating                          4.967500e+00  5.000000e+00  \n",
       "review_scores_accuracy                        4.990000e+00  5.000000e+00  \n",
       "review_scores_cleanliness                     4.990000e+00  5.000000e+00  \n",
       "review_scores_checkin                         5.000000e+00  5.000000e+00  \n",
       "review_scores_communication                   5.000000e+00  5.000000e+00  \n",
       "review_scores_location                        5.000000e+00  5.000000e+00  \n",
       "review_scores_value                           4.860000e+00  5.000000e+00  \n",
       "calculated_host_listings_count                4.700000e+01  3.400000e+02  \n",
       "calculated_host_listings_count_entire_homes   2.200000e+01  3.400000e+02  \n",
       "calculated_host_listings_count_private_rooms  3.000000e+00  2.740000e+02  \n",
       "calculated_host_listings_count_shared_rooms   0.000000e+00  4.000000e+00  \n",
       "reviews_per_month                             2.450000e+00  1.629000e+01  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstn._get_numeric_data().describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6e9f019-0e88-4e20-880e-a0dde33f005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The col_logger function will need to be brough in from the other notebooks\n",
    "\n",
    "This has been modified to include a 0 imputation value n such that transforamtion\n",
    "occurs on log(n) and not log(0) which is undefined.\n",
    "'''\n",
    "\n",
    "def col_logger(data_column, zero_imp = 1):\n",
    "    # Since log(0) is undefined, 0's must be treated as log(1)\n",
    "    return data_column.apply(lambda x: np.log(zero_imp) if x==0 else np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86081c09-6489-4a08-a952-305c59e5b349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_ft_maker(data_frame):\n",
    "    # Create a list of numerical columns\n",
    "    num_cols = list(data_frame._get_numeric_data().columns)\n",
    "\n",
    "    # Remove latitiude and longitude data as they were used previously to create distances\n",
    "    num_cols.remove('latitude')\n",
    "    num_cols.remove('longitude')\n",
    "\n",
    "    for col in num_cols:\n",
    "\n",
    "        # Find columsn with values between 0 and 1\n",
    "        if len(data_frame[col][(data_frame[col] < 1) & (data_frame[col] > 0)]) > 0:\n",
    "\n",
    "            # Determine the minimum value in that column, if it's 0, base the minimum\n",
    "            #  value off of the second smallest value in the column\n",
    "\n",
    "            if min(data_frame[col]) < 0:\n",
    "                print('CANT LOGARITHM A NEGATIVE NUMBER')\n",
    "                break\n",
    "\n",
    "            elif min(data_frame[col]) == 0:\n",
    "                # second smallest value\n",
    "                min_col_val = data_frame[col].sort_values().unique()[1]\n",
    "\n",
    "            else:\n",
    "                min_col_val = min(data_frame[col][(data_frame[col] < 1) & (data_frame[col] > 0)])\n",
    "\n",
    "            # Calculate a zero imputation value for use in the col_logger function\n",
    "            #  Take the natural log of the minimum value and round down\n",
    "            '''\n",
    "            This last step ensures that any zero values will be less than any positive\n",
    "            values after a log transformation.\n",
    "            '''\n",
    "            z_imp = np.exp(np.floor(np.log(min_col_val)))\n",
    "\n",
    "            # Transform the column:\n",
    "            data_frame[f'log_{col}'] = col_logger(data_frame[col], z_imp)\n",
    "\n",
    "        else:\n",
    "            # Otherwise, simply use defulat zero_imputation value of 1\n",
    "            data_frame[f'log_{col}'] = col_logger(data_frame[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd1c90e2-6514-4228-82f9-bf7bb294fe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3477 entries, 0 to 3476\n",
      "Data columns (total 75 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   id                                            3477 non-null   int64  \n",
      " 1   listing_url                                   3477 non-null   object \n",
      " 2   scrape_id                                     3477 non-null   int64  \n",
      " 3   last_scraped                                  3477 non-null   object \n",
      " 4   source                                        3477 non-null   object \n",
      " 5   name                                          3477 non-null   object \n",
      " 6   description                                   3464 non-null   object \n",
      " 7   neighborhood_overview                         2245 non-null   object \n",
      " 8   picture_url                                   3477 non-null   object \n",
      " 9   host_id                                       3477 non-null   int64  \n",
      " 10  host_url                                      3477 non-null   object \n",
      " 11  host_name                                     3477 non-null   object \n",
      " 12  host_since                                    3477 non-null   object \n",
      " 13  host_location                                 2683 non-null   object \n",
      " 14  host_about                                    2463 non-null   object \n",
      " 15  host_response_time                            3011 non-null   object \n",
      " 16  host_response_rate                            3011 non-null   object \n",
      " 17  host_acceptance_rate                          3067 non-null   object \n",
      " 18  host_is_superhost                             3476 non-null   object \n",
      " 19  host_thumbnail_url                            3477 non-null   object \n",
      " 20  host_picture_url                              3477 non-null   object \n",
      " 21  host_neighbourhood                            3364 non-null   object \n",
      " 22  host_listings_count                           3477 non-null   int64  \n",
      " 23  host_total_listings_count                     3477 non-null   int64  \n",
      " 24  host_verifications                            3477 non-null   object \n",
      " 25  host_has_profile_pic                          3477 non-null   object \n",
      " 26  host_identity_verified                        3477 non-null   object \n",
      " 27  neighbourhood                                 2245 non-null   object \n",
      " 28  neighbourhood_cleansed                        3477 non-null   object \n",
      " 29  neighbourhood_group_cleansed                  0 non-null      float64\n",
      " 30  latitude                                      3477 non-null   float64\n",
      " 31  longitude                                     3477 non-null   float64\n",
      " 32  property_type                                 3477 non-null   object \n",
      " 33  room_type                                     3477 non-null   object \n",
      " 34  accommodates                                  3477 non-null   int64  \n",
      " 35  bathrooms                                     0 non-null      float64\n",
      " 36  bathrooms_text                                3476 non-null   object \n",
      " 37  bedrooms                                      3061 non-null   float64\n",
      " 38  beds                                          3399 non-null   float64\n",
      " 39  amenities                                     3477 non-null   object \n",
      " 40  price                                         3477 non-null   object \n",
      " 41  minimum_nights                                3477 non-null   int64  \n",
      " 42  maximum_nights                                3477 non-null   int64  \n",
      " 43  minimum_minimum_nights                        3477 non-null   float64\n",
      " 44  maximum_minimum_nights                        3477 non-null   float64\n",
      " 45  minimum_maximum_nights                        3477 non-null   float64\n",
      " 46  maximum_maximum_nights                        3477 non-null   float64\n",
      " 47  minimum_nights_avg_ntm                        3477 non-null   float64\n",
      " 48  maximum_nights_avg_ntm                        3477 non-null   float64\n",
      " 49  calendar_updated                              0 non-null      float64\n",
      " 50  has_availability                              3477 non-null   object \n",
      " 51  availability_30                               3477 non-null   int64  \n",
      " 52  availability_60                               3477 non-null   int64  \n",
      " 53  availability_90                               3477 non-null   int64  \n",
      " 54  availability_365                              3477 non-null   int64  \n",
      " 55  calendar_last_scraped                         3477 non-null   object \n",
      " 56  number_of_reviews                             3477 non-null   int64  \n",
      " 57  number_of_reviews_ltm                         3477 non-null   int64  \n",
      " 58  number_of_reviews_l30d                        3477 non-null   int64  \n",
      " 59  first_review                                  2462 non-null   object \n",
      " 60  last_review                                   2462 non-null   object \n",
      " 61  review_scores_rating                          2462 non-null   float64\n",
      " 62  review_scores_accuracy                        2455 non-null   float64\n",
      " 63  review_scores_cleanliness                     2456 non-null   float64\n",
      " 64  review_scores_checkin                         2455 non-null   float64\n",
      " 65  review_scores_communication                   2456 non-null   float64\n",
      " 66  review_scores_location                        2455 non-null   float64\n",
      " 67  review_scores_value                           2455 non-null   float64\n",
      " 68  license                                       2071 non-null   object \n",
      " 69  instant_bookable                              3477 non-null   object \n",
      " 70  calculated_host_listings_count                3477 non-null   int64  \n",
      " 71  calculated_host_listings_count_entire_homes   3477 non-null   int64  \n",
      " 72  calculated_host_listings_count_private_rooms  3477 non-null   int64  \n",
      " 73  calculated_host_listings_count_shared_rooms   3477 non-null   int64  \n",
      " 74  reviews_per_month                             2462 non-null   float64\n",
      "dtypes: float64(21), int64(19), object(35)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "lstn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0753a598-26fb-443f-a5c9-9ff65090ffbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3287d6d4-6a71-4fa6-96bf-f468f65addc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_fn_2(data_frame, training_data):\n",
    "    # Find the remaining categorical columns:\n",
    "    cat_cols = list(data_frame.columns)\n",
    "    num_cols = list(data_frame._get_numeric_data().columns)\n",
    "\n",
    "    for col in num_cols:\n",
    "        cat_cols.remove(col)\n",
    "\n",
    "    # Some of these columns must be removed to be handled separately in advanced processing\n",
    "    remove_cols = ['amenities', 'host_about', 'name', 'neighborhood_overview', 'description']\n",
    "\n",
    "    for col in remove_cols:\n",
    "        cat_cols.remove(col)\n",
    "\n",
    "    # Create a new temporary dataframe with just the columns taht nee to be one hot encoded\n",
    "    #  otherwise, it will try to OHE the whole thing...\n",
    "    data_frame_temp = data_frame[cat_cols]\n",
    "    \n",
    "    # Add an if statment to fit_transform only if it's the training data:\n",
    "    if training_data == True:\n",
    "        # The instance of onehotencoder must be created as aglabal variable\n",
    "        #  ONLY DO THIS FOR TRAINING!!!\n",
    "        globals()['ohe_inst'] = OneHotEncoder(sparse_output = False, drop = 'first')\n",
    "        \n",
    "        # Create the ohe array from the temporary dataframe (fitted and transformed)\n",
    "        ohe_array = ohe_inst.fit_transform(data_frame_temp)\n",
    "\n",
    "    else:\n",
    "        # Create the ohe array from the temporary dataframe (transformed only)\n",
    "        ohe_array = ohe_inst.transform(data_frame_temp)\n",
    "    \n",
    "    # Make a dataframe from the array with the proper columns\n",
    "    ohe_array_df = pd.DataFrame(ohe_array, columns=ohe_inst.get_feature_names_out())\n",
    "    \n",
    "    # Drop the original cat_col columns in the original dataframe\n",
    "    data_frame.drop(columns=cat_cols, inplace=True)\n",
    "    \n",
    "    # Merge the OHE data into the new dataframe\n",
    "    data_frame = pd.merge(left = data_frame, \n",
    "                 right = ohe_array_df, \n",
    "                 left_index=True, right_index=True, \n",
    "                 how = 'outer')\n",
    "    \n",
    "    # Return the dataframe\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae31b4e-7ebb-463d-a9b5-f19118bb5c4c",
   "metadata": {},
   "source": [
    "# Advanced Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768b9b15-600f-4167-beea-a55e0d705a30",
   "metadata": {},
   "source": [
    "## Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51c4bb45-0145-4a16-ac27-ab8ccc600451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior to merging, add a prefix to the column names since it is text data and words tokenized from\n",
    "#  one column could overwrite with those of another.\n",
    "\n",
    "# Make a function to do this for all dataframes.\n",
    "\n",
    "def col_renamer(df, prefix):\n",
    "    new_names = [f'{prefix}_{col}' for col in df.columns]\n",
    "    df.columns = new_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89fe73ea-5551-4358-a4c8-1a046a4f2f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amentiy_count_maker(data_frame):\n",
    "    # Use a regular expression to extract the amenities which are between quotes.\n",
    "    #  Code adapted from this source: https://stackoverflow.com/questions/1454913/regular-expression-to-find-a-string-included-between-two-characters-while-exclud\n",
    "    # Also helpful:  https://regex101.com/\n",
    "    regex_string = '(?<=\")[^\"]+(?=\"[,\\]])'\n",
    "    \n",
    "    # Using regex as before, find the number of amenities for every listing and store to a new column\n",
    "    data_frame['amen_cnt'] = data_frame.amenities.apply(lambda x: len(re.findall(regex_string, x)))\n",
    "\n",
    "    # Create a log transformed column, setting the zero imputation value to e^-1\n",
    "    data_frame['log_amen_cnt'] = col_logger(data_frame['amen_cnt'], np.exp(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58d4db92-bec8-42a7-b264-6e2ed19ac8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amenity_maker(data_frame, training_data):\n",
    "    # Use a regular expression to extract the amenities which are between quotes.\n",
    "    #  Code adapted from this source: https://stackoverflow.com/questions/1454913/regular-expression-to-find-a-string-included-between-two-characters-while-exclud\n",
    "    # Also helpful:  https://regex101.com/\n",
    "    regex_string = '(?<=\")[^\"]+(?=\"[,\\]])'\n",
    "\n",
    "    amn_lst = []\n",
    "\n",
    "    for string_lists in data_frame.amenities:\n",
    "        a_list = re.findall(regex_string, string_lists)\n",
    "        for amenity in a_list:\n",
    "            amn_lst.append(amenity)\n",
    "\n",
    "    # Create a pandas series of all amenities and their number of occurences\n",
    "    amn_counts = pd.Series(amn_lst).value_counts(ascending=False)\n",
    "\n",
    "    # Filter the datafarme to use only words that appear in 99% of posts\n",
    "    #  THIS IS REQUIRED GIVEN THAT min_df IS IGNORED BY COUNT VECTORISZER WITH CUSTOM DICTIONARIES\n",
    "    #  Create a vocab variable by using the index attribute to get the list of amenities\n",
    "    amn_vocab = amn_counts[amn_counts >= 35].index\n",
    "\n",
    "    if training_data == True:\n",
    "        # Use countevectorizer to one hot encode all the amenities\n",
    "        #  Use the vocab to get only the amenities encoded\n",
    "        #  NOTE:  Set the 'token_pattern' to the regex string so it finds the exact same tokens as were found previously\n",
    "        globals()[f'cvec_amen'] = CountVectorizer(lowercase=False,\n",
    "                               vocabulary=amn_vocab,\n",
    "                               ngram_range=(1, 1),\n",
    "                               token_pattern=regex_string,\n",
    "                              )\n",
    "\n",
    "        # Create a new dataframe with the count vectorized data from the amenities column\n",
    "        amen_df = pd.DataFrame(globals()[f'cvec_amen'].fit_transform(data_frame.amenities).todense(), \n",
    "                     columns = globals()[f'cvec_amen'].get_feature_names_out())\n",
    "    \n",
    "    else:\n",
    "        # Create a new dataframe with the count vectorized data from the amenities column\n",
    "        amen_df = pd.DataFrame(globals()[f'cvec_amen'].transform(data_frame.amenities).todense(), \n",
    "                     columns = globals()[f'cvec_amen'].get_feature_names_out())\n",
    "        \n",
    "    # Rename the columns of amen_df\n",
    "    col_renamer(amen_df, 'amen')\n",
    "    \n",
    "    # Merge amen_df into the lstn dataframe\n",
    "    return pd.merge(left = data_frame, \n",
    "                    right = amen_df, \n",
    "                    left_index=True, right_index=True, \n",
    "                    how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b06e100-9cfb-49d3-a28e-16ff9129ee9a",
   "metadata": {},
   "source": [
    "## Count Vectorize and Add Columns for Name, Description, Neigb. Overview, and Host About"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7ab2670-1668-4b9e-8f68-23eb180aff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Write a function that will:\n",
    "* vectorize the columns\n",
    "* create a new df for those columns\n",
    "* rename those columns\n",
    "* merge into lstn\n",
    "* Store the count vectorizer objects so that .transform can be later \n",
    "run on testing/validation datasets\n",
    "'''\n",
    "\n",
    "def text_col_cvec(data_frame, training_data):\n",
    "    \n",
    "    # Provide all the columns that need to be word vectorized\n",
    "    text_cols = ['name', 'description', 'host_about', 'neighborhood_overview']\n",
    "    \n",
    "    for col in text_cols:\n",
    "        # print(f'before: {data_frame.shape}')\n",
    "        \n",
    "        # Create a temporary variable to establish the pandas series based on the list\n",
    "        column_data = data_frame[col]\n",
    "        \n",
    "        # Do fit_transform only if training_data = True\n",
    "        if training_data == True:\n",
    "            \n",
    "            # Instantiate count vectorizer\n",
    "            globals()[f'cvec_{col}'] = CountVectorizer(ngram_range=(1, 4), min_df=0.01)\n",
    "\n",
    "            # Create a new dataframe with the count vectorized data from the selected column\n",
    "            cvec_df = pd.DataFrame(globals()[f'cvec_{col}'].fit_transform(column_data).todense(), \n",
    "                         columns = globals()[f'cvec_{col}'].get_feature_names_out())\n",
    "            \n",
    "        else:\n",
    "            # Create a new dataframe with the count vectorized data from the selected column\n",
    "            cvec_df = pd.DataFrame(globals()[f'cvec_{col}'].transform(column_data).todense(), \n",
    "                         columns = globals()[f'cvec_{col}'].get_feature_names_out())\n",
    "\n",
    "        # Rename the columns\n",
    "        col_renamer(cvec_df, col)\n",
    "        \n",
    "        # print(cvec_df.shape)\n",
    "\n",
    "        # Merge into the main dataframe\n",
    "        data_frame = pd.merge(left = data_frame, \n",
    "             right = cvec_df, \n",
    "             left_index=True, right_index=True, \n",
    "             how = 'outer')\n",
    "        \n",
    "        # print(f'after: {data_frame.shape} \\n')\n",
    "        \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6e8677-c5e4-42f1-bd19-8a67ddb22c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaced50-3f7c-4d62-8347-b86cdf75d527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ea67319-2f7f-43ca-8ec5-61937446f72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_formatter_2(data_frame, training_data):\n",
    "    print(f'start: {data_frame.shape[1]}')\n",
    "    \n",
    "    col_dropper(data_frame)\n",
    "    print(f'col_dropper: {data_frame.shape[1]}')\n",
    "\n",
    "    data_fixer(data_frame)\n",
    "    print(f'data_fixer: {data_frame.shape[1]}')\n",
    "\n",
    "    data_imputer(data_frame)\n",
    "    print(f'data_imputer: {data_frame.shape[1]}')\n",
    "\n",
    "    simp_num_ft(data_frame)\n",
    "    print(f'simp_num_ft: {data_frame.shape[1]}')\n",
    "\n",
    "    dist_ft_adder(data_frame)\n",
    "    print(f'dist_ft_adder: {data_frame.shape[1]}')\n",
    "\n",
    "    log_ft_maker(data_frame)\n",
    "    print(f'log_ft_maker: {data_frame.shape[1]}')\n",
    "\n",
    "    data_frame = ohe_fn_2(data_frame, training_data)\n",
    "    print(f'ohe_fn: {data_frame.shape[1]}')\n",
    "\n",
    "    amentiy_count_maker(data_frame)\n",
    "    print(f'amentiy_count_maker: {data_frame.shape[1]}')\n",
    "\n",
    "    data_frame = amenity_maker(data_frame, training_data)\n",
    "    print(f'amenity_maker: {data_frame.shape[1]}')\n",
    "\n",
    "    data_frame = text_col_cvec(data_frame, training_data)\n",
    "    print(f'text_col_cvec: {data_frame.shape[1]}')\n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77f6d4b6-7163-4427-baf4-507d4db93045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 75\n",
      "col_dropper: 41\n",
      "data_fixer: 41\n",
      "data_imputer: 41\n",
      "simp_num_ft: 44\n",
      "dist_ft_adder: 45\n",
      "log_ft_maker: 72\n",
      "ohe_fn: 160\n",
      "amentiy_count_maker: 162\n",
      "amenity_maker: 315\n",
      "text_col_cvec: 12926\n"
     ]
    }
   ],
   "source": [
    "# Import the Training Data\n",
    "lstn = master_formatter_2(lstn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a9a0292-c226-4102-8110-f2ea7f1e8a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 75\n",
      "col_dropper: 41\n",
      "data_fixer: 41\n",
      "data_imputer: 41\n",
      "simp_num_ft: 44\n",
      "dist_ft_adder: 45\n",
      "log_ft_maker: 72\n",
      "ohe_fn: 160\n",
      "amentiy_count_maker: 162\n",
      "amenity_maker: 315\n",
      "text_col_cvec: 12926\n"
     ]
    }
   ],
   "source": [
    "testing = pd.read_csv('../data/listings_test.csv')\n",
    "testing_now = master_formatter_2(testing, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59af5783-4171-4711-b380-1524140f94cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 12926)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_now.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "278bf259-eb11-40b4-8b4e-fb5860fa30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstn.to_csv('../data/prepped_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4ed1241-6d8c-4442-b65e-5df1e37216a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing.to_csv('../data/prepped_testing.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
